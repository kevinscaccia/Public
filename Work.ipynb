{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Work.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crA4PaD_uWOf",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkEMR7gPuUR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd #\n",
        "import numpy as np #\n",
        "import math, time\n",
        "from IPython.display import clear_output  # clear cell output\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, CuDNNLSTM, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "####### LOAD DATASET\n",
        "url = 'https://raw.githubusercontent.com/kevinscaccia/data/master/hobbit_02-12-2013.csv'\n",
        "df = pd.read_csv(url, usecols=[7,8,9])  # latency, jitter and packet_loss\n",
        "print(df.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qikkHIlMubBI",
        "colab_type": "text"
      },
      "source": [
        "## LSTM Module Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gBHJ551uf84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################################\n",
        "# GENERIC CLASS THAT IMPLEMENTS AN LSTM NETWORK AND FORECAST THE NEXT \n",
        "# N_STEPS_OUT FUTURE VALUES\n",
        "#\n",
        "class LSTM_Module:\n",
        "    #######\n",
        "    # CONSTRUCTOR\n",
        "    #\n",
        "    def __init__(self, data, n_steps_in, n_steps_out):\n",
        "        ####### MODEL HYPER-PARAMETERS\n",
        "        self.n_steps_in = n_steps_in  # past window size\n",
        "        self.n_steps_out = n_steps_out  # future output window\n",
        "        self.n_features = 1  # each point dimension (escalar)\n",
        "        ####### DATA\n",
        "        self.data = data  # entire data\n",
        "        self.train_data = None  # entire train data\n",
        "        self.test_data = None  # entire test data\n",
        "        self.train_x = None  # train input, shape: [train_len, n_steps_in]\n",
        "        self.train_y = None  # train output, shape: [train_len, n_steps_out]\n",
        "        self.test_x = None  # test input, shape: [test_len, n_steps_in]\n",
        "        self.test_y = None  # test OUTPUT, shape: [test_len, n_steps_in]\n",
        "        ####### MODEL INFO\n",
        "        self.model = None  # model reference\n",
        "        self.model_history = None  # model train history\n",
        "        self.train_scaler = None  # train data scaler\n",
        "        self.test_scaler = None  # test data scaler\n",
        "        self.predicted_scaled = None  # predicted values (model scale)\n",
        "        self.predicted = None  # predicted values (real scale)\n",
        "        \n",
        "        \n",
        "    #######\n",
        "    # LOAD AND SPLIT DATA\n",
        "    #    \n",
        "    def load_data(self, start, end, percent_train):\n",
        "        ###### DATA LENGTH\n",
        "        data = self.data.values[start:end]\n",
        "        data = data.astype('float32')  # to float32\n",
        "        data = data.reshape(data.shape[0])\n",
        "        ###### SPLIT TRAIN AND TEST\n",
        "        split_index = int(len(data)*percent_train) # split index\n",
        "        train_data = data[:split_index]\n",
        "        test_data = data[split_index:]\n",
        "        ####### DATA SCALER\n",
        "        self.train_scaler = MinMaxScaler(feature_range=(0, 1))  # scale between [0,1]\n",
        "        self.train_data  = self.train_scaler.fit_transform(train_data.reshape(-1, 1))  # transform only train data\n",
        "        self.test_scaler =  MinMaxScaler(feature_range=(0, 1))  # scale between [0,1]\n",
        "        self.test_data = self.test_scaler.fit_transform(test_data.reshape(-1, 1))  # transform only train data\n",
        "        ###### DATA WINDOW SPLIT\n",
        "        x_train, y_train = LSTM_Module.split_sequence(train_data, self.n_steps_in, self.n_steps_out)\n",
        "        self.test_x, self.test_y = LSTM_Module.split_sequence(test_data, self.n_steps_in, self.n_steps_out)\n",
        "        # reshape from [samples, timesteps] into [samples, timesteps, features] for LSTM INPUT\n",
        "        self.train_x = x_train.reshape((x_train.shape[0], x_train.shape[1], self.n_features))\n",
        "        self.train_y = y_train.reshape((y_train.shape[0], y_train.shape[1]))\n",
        "\n",
        "        \n",
        "    #######\n",
        "    # DEFINE AND TRAIN LSTM NETWORK \n",
        "    #\n",
        "    def train_model(self, hidden_1=1, hidden_2=1, epochs=10):\n",
        "        ###### DEFINE MODEL\n",
        "        model = Sequential()\n",
        "        model.add(CuDNNLSTM(hidden_1, return_sequences=True, input_shape=(self.n_steps_in, self.n_features)))\n",
        "        model.add(CuDNNLSTM(hidden_2))\n",
        "        model.add(Dense(self.n_steps_out, ))# activation='sigmoid'))\n",
        "        ###### COMPILE MODEL\n",
        "        model.compile(optimizer='adam', loss='mse')\n",
        "        ###### TRAIN MODEL\n",
        "        self.model_history = model.fit(self.train_x, self.train_y, \n",
        "                   epochs=epochs)\n",
        "        clear_output()  # clear console output\n",
        "        #['acc', 'loss', 'val_acc', 'val_loss']\n",
        "        #print(\"Model acc: {}\\n Model loss: {}\", \n",
        "        #      self.model_history['acc'], self.model_history['loss'])\n",
        "        self.model = model\n",
        "    \n",
        "    \n",
        "    #######\n",
        "    # PREDICTC N STEPS AHEAD THE TRAIN DATA\n",
        "    #\n",
        "    def predict(self, steps_ahead=1):\n",
        "        ###### PREDICTED VALUES\n",
        "        history = self.train_x[-1]  # last train value\n",
        "        history = history.reshape(-1)\n",
        "        ###### PREDICTS AND APPEND(PREDICTION) TO THE HISTORY(AND USES IT)\n",
        "        for i in range(0, steps_ahead*self.n_steps_in, self.n_steps_out):\n",
        "            input_values = np.array([history[-self.n_steps_in:]])  # last predicted value\n",
        "            inn = input_values.reshape(1, self.n_steps_in,1)\n",
        "            pred = self.model.predict(np.array(inn))  # predict\n",
        "            pred = pred.reshape(-1)  # reshape\n",
        "            history = np.concatenate([history, pred])  # concatenate prediction to data\n",
        "        ###### STORE PREDICTION\n",
        "        history = history.reshape(-1, 1)\n",
        "        self.predicted_scaled = history  # model scale, between [0,1]\n",
        "        ###### RETURN TO THE PROBLEM REAL SCALE\n",
        "        self.predicted = self.train_scaler.inverse_transform(history)  # rescale to original metric\n",
        "    \n",
        "    \n",
        "    #######\n",
        "    # PLOT PREDICTED\n",
        "    #\n",
        "    def plot_predicted(self, steps_ahead=1):\n",
        "        len_ahead = steps_ahead*self.n_steps_out\n",
        "        plt.figure(figsize=(10, 4), dpi=80, facecolor='w', edgecolor='k'); plt.grid(True)\n",
        "        plt.ylabel(\"Jitter\"); plt.xlabel(\"Time\"); plt.grid(True)\n",
        "        ###### PREDICTED VALUES\n",
        "        plt_pred_values = self.predicted[self.n_steps_in:self.n_steps_in+len_ahead].reshape(-1)\n",
        "        ###### REAL TEST VALUES\n",
        "        plt_test_values = self.test_y[:len_ahead, 0].reshape(-1)\n",
        "        #\n",
        "        plt.plot(plt_test_values, 'b')\n",
        "        plt.plot(plt_pred_values, 'r')\n",
        "        plt.show()\n",
        "    \n",
        "    \n",
        "    #######\n",
        "    # SPLIT TRAIN TEST AUXILIARY FUNCTION\n",
        "    #\n",
        "    def split_sequence(sequence, n_steps_in, n_steps_out):\n",
        "        X, y = list(), list()\n",
        "        for i in range(len(sequence)):\n",
        "            # find the end of this pattern\n",
        "            end_ix = i + n_steps_in\n",
        "            out_end_ix = end_ix + n_steps_out\n",
        "            # check if we are beyond the sequence\n",
        "            if out_end_ix > len(sequence):\n",
        "                break\n",
        "            # gather input and output parts of the pattern\n",
        "            seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
        "            X.append(seq_x)\n",
        "            y.append(seq_y)\n",
        "        return np.array(X), np.array(y)\n",
        "########################################################\n",
        "########################################################\n",
        "########################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fi-sN-abu-FB",
        "colab_type": "text"
      },
      "source": [
        "## MLP Module Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7qbza-Ku9dS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################################\n",
        "# MLP CLASS THAT USES FORECASTED VALUES(2*N_STEPS_OUT) TO FORECAST THE LOSS\n",
        "# (N_STEPS_OUT FUTURE LOSS VALUES)\n",
        "#\n",
        "class MLP_Module():\n",
        "    #######\n",
        "    # CONSTRUCTOR\n",
        "    #\n",
        "    def __init__(self, loss_data, jitter_model, latency_model):\n",
        "        ####### DATA\n",
        "        self.loss_data = loss_data  # loss data\n",
        "        self.train_data = None  \n",
        "        self.train_data_x = list()  # \n",
        "        self.train_data_y = list()\n",
        "        ####### MODELS\n",
        "        self.jitter_model = jitter_model\n",
        "        self.latency_model = latency_model\n",
        "        ####### MLP MODEL PARAMETERS\n",
        "        self.model = None  # model reference\n",
        "        self.n_steps_out = jitter_model.n_steps_out\n",
        "        self.input_dim = jitter_model.n_steps_out + latency_model.n_steps_out\n",
        "        self.X = None\n",
        "        self.Y = None\n",
        "    \n",
        "    #####\n",
        "    # Load train data\n",
        "    #\n",
        "    def load_train_data(self,):\n",
        "        jitter_seq = self.jitter_model.train_data.reshape(-1)\n",
        "        latency_seq = self.latency_model.train_data.reshape(-1)\n",
        "        loss_seq = self.loss_data\n",
        "        X, Y = list(), list()\n",
        "        for i in range(0, len(jitter_seq), self.n_steps_out):\n",
        "            # organize in blocks\n",
        "            steps = jitter_seq[i:i+self.n_steps_out].reshape(-1)\n",
        "            steps = np.concatenate([steps, latency_seq[i:i+self.n_steps_out].reshape(-1) ])\n",
        "            loss_steps = loss_seq[i:i+self.n_steps_out]\n",
        "            # populate list\n",
        "            X.append(steps)\n",
        "            Y.append(loss_steps)\n",
        "        self.X = np.array(X)\n",
        "        self.Y = np.array(Y)\n",
        "        \n",
        "    #####\n",
        "    # Train model\n",
        "    #\n",
        "    def train_model(self, n_hidden_1, n_hidden_2, epochs=10):\n",
        "        latency_input = self.latency_model.train_data.reshape(-1)\n",
        "        jitter_input = self.jitter_model.train_data.reshape(-1)\n",
        "        self.network_input = np.concatenate([jitter_input,latency_input])\n",
        "        ###\n",
        "        # create model\n",
        "        self.model = model = Sequential()\n",
        "        model.add(Dense(n_hidden_1, input_shape=(self.n_steps_out*2,)))\n",
        "        model.add(Dense(n_hidden_2, kernel_initializer='normal', activation='relu'))\n",
        "        model.add(Dense(self.n_steps_out, kernel_initializer='normal'))\n",
        "        # Compile model\n",
        "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "        #model.summary()\n",
        "        model.fit(self.X, self.Y, epochs=epochs)\n",
        "        \n",
        "    #####\n",
        "    # Predict next n_steps_out\n",
        "    #\n",
        "    def predict(self,):\n",
        "        n = len(self.jitter_model.train_data)\n",
        "        loss_seq_test = df[' packet_loss'][n:n+self.n_steps_out].values\n",
        "        jitter_seq_test = self.jitter_model.test_data[:self.n_steps_out].reshape(-1)\n",
        "        latency_seq_test = self.latency_model.test_data[:self.n_steps_out].reshape(-1)\n",
        "        #\n",
        "        X, Y = list(), list()\n",
        "        for i in range(0, len(jitter_seq_test), self.n_steps_out):\n",
        "            # organize in blocks\n",
        "            steps = jitter_seq_test[i:i+self.n_steps_out].reshape(-1)\n",
        "            steps = np.concatenate([steps, latency_seq_test[i:i+self.n_steps_out].reshape(-1) ])\n",
        "            print(\"-->\",steps.shape)\n",
        "            loss_steps = loss_seq_test[i:i+self.n_steps_out]\n",
        "            # populate list\n",
        "            X.append(steps)\n",
        "            Y.append(loss_steps)\n",
        "        ################################### \n",
        "        x_value = np.array(X)\n",
        "        y_value = self.model.predict(x_value)\n",
        "        ###################################\n",
        "        plt.plot(loss_seq_test, 'y')\n",
        "        plt.plot(y_value.reshape(-1),'r')\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSVroJNzAHME",
        "colab_type": "text"
      },
      "source": [
        "## Hybrid Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sf4MfqSv2Ir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HybridModel():\n",
        "    def __init__(self, df):\n",
        "        self.n_steps_out = 20\n",
        "        self.n_steps_in = 10\n",
        "        self.start_data = 1000\n",
        "        self.end_data = 3000\n",
        "        self.df = df\n",
        "        self.percent_train = 0.9\n",
        "        ################### Models\n",
        "        self.jitter_model = None\n",
        "        self.latency_model = None\n",
        "        self.mlp_module = None\n",
        "        ################### HYPER-PARAMETERS JITTER LSTM\n",
        "        self.jitter_lstm_hidden_1 = 20\n",
        "        self.jitter_lstm_hidden_2 = 20\n",
        "        self.jitter_lstm_epochs = 100\n",
        "        self.jitter_predict_steps_ahead = 1\n",
        "        ################### HYPER-PARAMETERS LATENCY LSTM\n",
        "        self.latency_lstm_hidden_1 = 20\n",
        "        self.latency_lstm_hidden_2 = 20\n",
        "        self.latency_lstm_epochs = 100\n",
        "        self.latency_predict_steps_ahead = 1\n",
        "        ################### HYPER-PARAMETERS MLP \n",
        "        self.mlp_hidden_1 = 10\n",
        "        self.mlp_hidden_2 = 10\n",
        "        self.mlp_epochs = 100\n",
        "        ###################\n",
        "        #################\n",
        "        \n",
        "    def load_models(self,):\n",
        "        self.jitter_model = LSTM_Module(data=self.df[' jitter'], n_steps_in=self.n_steps_in, n_steps_out=self.n_steps_out)\n",
        "        self.jitter_model.load_data(start=self.start_data, end=self.end_data, percent_train=self.percent_train)\n",
        "        #\n",
        "        self.latency_model = LSTM_Module(data=self.df[' latency'], n_steps_in=self.n_steps_in, n_steps_out=self.n_steps_out)\n",
        "        self.latency_model.load_data(start=self.start_data, end=self.end_data, percent_train=self.percent_train)\n",
        "        #\n",
        "    \n",
        "    def train_models(self,): \n",
        "        print(\"Training LSTM Jitter Module\")\n",
        "        self.jitter_model.train_model(hidden_1=self.jitter_lstm_hidden_1, \n",
        "                                      hidden_2=self.jitter_lstm_hidden_1,\n",
        "                                      epochs=self.jitter_lstm_epochs)\n",
        "        \n",
        "        print(\"Training LSTM Latency Module\")\n",
        "        self.latency_model.train_model(hidden_1=self.latency_lstm_hidden_1, \n",
        "                                       hidden_2=self.latency_lstm_hidden_2, \n",
        "                                       epochs=self.latency_lstm_epochs)\n",
        "        #\n",
        "        # arrumar aqui\n",
        "        #\n",
        "        self.loss_seq = df[' packet_loss'][0:len(self.latency_model.train_data)].values\n",
        "        self.mlp_module = MLP_Module(self.loss_seq, self.jitter_model, self.latency_model)\n",
        "        self.mlp_module.load_train_data() \n",
        "        print(\"Training MLP Module\")\n",
        "        \n",
        "        self.mlp_module.train_model(self.mlp_hidden_1,\n",
        "                                    self.mlp_hidden_2,\n",
        "                                    self.mlp_epochs)\n",
        "        \n",
        "        \n",
        "    def predict(self,):\n",
        "        self.jitter_model.predict(steps_ahead=self.jitter_predict_steps_ahead)\n",
        "        self.latency_model.predict(steps_ahead=self.latency_predict_steps_ahead)\n",
        "        self.mlp_module.predict()\n",
        "########################################################\n",
        "########################################################\n",
        "########################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx7O_6HqdeAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_time = time.time()\n",
        "model = HybridModel(df)\n",
        "model.load_models()\n",
        "model.train_models()\n",
        "model.predict()\n",
        "print(\"time: {}s\".format( time.time() - start_time))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcKjZstneNT_",
        "colab_type": "text"
      },
      "source": [
        "## Auxiliary Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMnB8XXkeM3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_informations(df, model):\n",
        "    start_data = model.start_data\n",
        "    end_data = model.end_data\n",
        "    #\n",
        "    plt.ylabel(\"Jitter\")\n",
        "    plt.plot(df[' jitter'].values[start_data:end_data])\n",
        "    plt.show()\n",
        "    plt.ylabel(\"Latency\")\n",
        "    plt.plot(df[' latency'].values[start_data:end_data])\n",
        "    plt.show()\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.plot(df[' packet_loss'].values[start_data:end_data])\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ0ofpaqdpYh",
        "colab_type": "text"
      },
      "source": [
        "## Testes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RGABdKCdsb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "jitter_model = LSTM_Module(data=df[' jitter'], \n",
        "                           n_steps_in=50, n_steps_out=50)\n",
        "jitter_model.load_data(start=1000, end=9000, \n",
        "                       percent_train=0.8)\n",
        "################### TRAIN MODEL\n",
        "jitter_model.train_model(hidden_1=100, hidden_2=100, epochs=500)\n",
        "jitter_model.predict(steps_ahead=10)\n",
        "jitter_model.plot_predicted(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sclykxvi5_34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrVMMnHHa6Lx",
        "colab_type": "text"
      },
      "source": [
        "## Notas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGj4kQ6IcDtE",
        "colab_type": "text"
      },
      "source": [
        "#### Perguntas mais relevantes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcdtJGObaba9",
        "colab_type": "text"
      },
      "source": [
        "É Possível a partir do dataset original retirar os parâmetros **jitter**, **latency/delay** e **loss** ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOb9TBawam_E",
        "colab_type": "text"
      },
      "source": [
        "Posso continuar utilizando o modelo de forma a prever os parâmetros em uma janela **t** e utilizar a previsão que o modelo fez para prever os valores na janela **t+1**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRhQBRS7bQ3b",
        "colab_type": "text"
      },
      "source": [
        "Ou utilizar o modelo para prever os parâmetros em um tempo **t**, depois, com a captura dos **valores reais**, prever o tempo **t+1** (Walk-forward Validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9_DD64obj9n",
        "colab_type": "text"
      },
      "source": [
        "Tenho dois modelos (LSTM e MLP), devo utilizar os mesmos **dados de treino para eles**? (mesma partição para treino, feita a partir do dataset original, já escalada entre [0,1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ3beofSiskq",
        "colab_type": "text"
      },
      "source": [
        "É possível treinar os dois modelos separadamente? Ou é necessário que os dados de treino da LSTM sejam os mesmos dados utilizados no treino da MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKreqWdqb_OY",
        "colab_type": "text"
      },
      "source": [
        "#### Perguntas menos relevantes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZTo3iH6b1Fu",
        "colab_type": "text"
      },
      "source": [
        "Quais outras técnicas para realizar a validação do modelo? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDIpu-vki6mZ",
        "colab_type": "text"
      },
      "source": [
        "#### Informações"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAcnvMSoi8h9",
        "colab_type": "text"
      },
      "source": [
        "Entrada da LSTM:\n",
        "> (samples , input_window, feature_dimension)\n",
        "\n",
        "Saída da LSTM:\n",
        "> (samples , output_window,)\n",
        "\n",
        "Entrada da MLP:\n",
        "> (output_window*2,)\n",
        "\n",
        "Saída da MLP:\n",
        "> (output_window,)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}
